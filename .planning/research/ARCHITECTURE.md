# Architecture Research

**Domain:** Monorepo feature integration (backup, health ingest, cross-domain insights, unified search) into Express.js + React + PM2 + JSON file architecture
**Researched:** 2026-02-26
**Confidence:** HIGH â€” all five features follow well-established patterns and align with the existing PortOS architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            Client (React/Vite :5555)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Cmd+K       â”‚  â”‚  MeatSpace   â”‚  â”‚  Insights    â”‚  â”‚  Backup        â”‚  â”‚
â”‚  â”‚  Overlay     â”‚  â”‚  Health Tab  â”‚  â”‚  Page/Panel  â”‚  â”‚  Status Widget â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚ HTTP/WS          â”‚ HTTP             â”‚ HTTP             â”‚ HTTP      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                       Express API Server (:5554)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  /api/search â”‚  â”‚  /api/       â”‚  â”‚  /api/       â”‚  â”‚  /api/backup   â”‚  â”‚
â”‚  â”‚  (fan-out)   â”‚  â”‚  meatspace/  â”‚  â”‚  insights    â”‚  â”‚  (CRUD +       â”‚  â”‚
â”‚  â”‚              â”‚  â”‚  health      â”‚  â”‚  (read-only) â”‚  â”‚   trigger)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                  â”‚                   â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  searchSvc   â”‚  â”‚  appleHealth â”‚  â”‚  insightsSvc â”‚  â”‚  backupSvc     â”‚  â”‚
â”‚  â”‚  (aggregator)â”‚  â”‚  Svc (parse  â”‚  â”‚  (correlate  â”‚  â”‚  (scheduler +  â”‚  â”‚
â”‚  â”‚              â”‚  â”‚  + store)    â”‚  â”‚  + derive)   â”‚  â”‚   rsync/cp)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                  â”‚                   â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         Data Layer (./data/)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ brain/   â”‚  â”‚ meatspaceâ”‚  â”‚ digital- â”‚  â”‚ cos/     â”‚  â”‚ External     â”‚  â”‚
â”‚  â”‚ memory/  â”‚  â”‚ /health/ â”‚  â”‚ twin/    â”‚  â”‚ agents/  â”‚  â”‚ Drive Mount  â”‚  â”‚
â”‚  â”‚ apps.jsonâ”‚  â”‚ genome/  â”‚  â”‚          â”‚  â”‚ runs/    â”‚  â”‚              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Boundaries

### New Components

| Component | Responsibility | Communicates With | Files |
|-----------|---------------|-------------------|-------|
| **Backup Service** | Schedule and execute incremental backup of `./data/` to external drive; track run history and status | fileUtils, PM2 ecosystem (optional cron), Socket.IO for status | `server/services/backup.js`, `server/routes/backup.js` |
| **Apple Health Ingest** | Accept POST with XML body from Health Auto Export app; stream-parse Apple Health XML; normalize and persist to JSON | meatspace data files, Zod validation, meatspaceHealth service | `server/services/appleHealth.js`, `server/routes/appleHealth.js` (or nested under meatspace routes) |
| **Cross-Insights Engine** | Read from genome, health, taste, personality, and body data; compute derived correlations; cache results | genome service, digital-twin service, meatspace services, taste-questionnaire service (read-only consumers) | `server/services/insights.js`, `server/routes/insights.js` |
| **Unified Search API** | Receive query, fan out to domain-specific search functions, merge and rank results, return unified response | memory service (BM25 + vector), brain service, genome service, apps service, history service, digital-twin service, meatspace services | `server/services/search.js`, `server/routes/search.js` |
| **Cmd+K Overlay** | Client-side keyboard-triggered modal; debounced input; call unified search API; render categorized results with navigation | `services/api.js` (HTTP), React Router (for navigation to results) | `client/src/components/CommandPalette.jsx`, `client/src/hooks/useCommandPalette.js` |

### Existing Components Touched

| Component | Change | Impact |
|-----------|--------|--------|
| `server/index.js` | Mount 3-4 new route files | Minimal â€” follows existing import + `app.use()` pattern |
| `client/src/components/Layout.jsx` | Render `<CommandPalette />` as a sibling to `<Outlet />` | Minimal â€” one component addition, global keyboard listener |
| `server/lib/fileUtils.js` | No changes needed â€” `PATHS.meatspace` already exists | None |
| `server/lib/meatspaceValidation.js` | Add Zod schemas for Apple Health ingest payloads | Additive |
| `ecosystem.config.cjs` | No new ports needed â€” all features run within the existing Express server process | None |
| MeatSpace routes/services | Add health sub-routes or a sibling route file for Apple Health | Additive |

## Data Flow

### 1. Backup Flow

```
Timer/Manual Trigger
    â†“
backupService.runBackup()
    â†“
rsync ./data/ â†’ /Volumes/[external-drive]/portos-backup/
    â†“
Record result to data/backup-history.json
    â†“
Socket.IO emit('backup:status', { ... })
    â†“
Client backup widget updates
```

**Key decisions:**
- Use `rsync --archive --delete --exclude` (or `cp -a` as fallback) for incremental copy. rsync is already available on macOS.
- Scheduler uses the same `setInterval` + time-check pattern as `brainScheduler.js` â€” not a new PM2 process, not node-cron. This keeps consistency with existing scheduling patterns (brainScheduler checks every 60s against a target time).
- Backup state (last run, next scheduled, history) persists to `data/backup-history.json`.
- Mount path for external drive is stored in a config file (`data/backup-config.json`) â€” user configures once.

### 2. Apple Health Ingest Flow

```
Health Auto Export App (HTTP POST)
    â†“
POST /api/meatspace/health/import
    â†“
Zod validates wrapper (metadata, content-type)
    â†“
appleHealthService.ingestXML(xmlBuffer)
    â†“
sax/expat stream parser (NOT full DOM parse â€” files can be 500MB+)
    â†“
Normalize records â†’ { type, date, value, unit, source }
    â†“
Batch-write to data/meatspace/health/{type}.json
    â†“
Return import stats { imported: N, skipped: N, errors: N }
```

**Key decisions:**
- Stream parsing is essential. Apple Health XML exports are regularly 200-500MB. A DOM parser would OOM the 500MB memory limit on portos-server. Use `sax` (event-based XML parser, zero dependencies, 15+ years mature) or `@oozcitak/saxes` (maintained fork).
- Split ingested data by record type (e.g., `heart-rate.json`, `steps.json`, `weight.json`, `sleep.json`) rather than one giant file. This matches the existing meatspace pattern of domain-specific JSON files.
- Deduplication by `(type, date, source)` composite key â€” Apple Health exports contain historical data on every export.
- Express already has `express.json({ limit: '50mb' })` and `express.urlencoded({ limit: '50mb' })` configured. For raw XML, add `express.raw({ type: 'application/xml', limit: '600mb' })` on the specific route, or accept base64-encoded XML inside a JSON POST (matching the existing TSV import pattern).
- Alternatively, accept the XML as multipart upload via the existing `uploads` infrastructure.

### 3. Cross-Insights Engine Flow

```
GET /api/insights (or GET /api/insights/:domain)
    â†“
insightsService.computeInsights()
    â†“
Read (parallel):
  â”œâ”€â”€ genome service â†’ SNP markers, longevity
  â”œâ”€â”€ meatspace services â†’ blood, body, alcohol, lifestyle
  â”œâ”€â”€ digital-twin â†’ taste, personality traits, soul profile
  â””â”€â”€ (future) apple health â†’ heart rate trends, sleep patterns
    â†“
Correlation rules (declarative):
  genome(APOE Îµ4) + blood(LDL) â†’ cardiovascular risk insight
  genome(CYP1A2) + lifestyle(caffeine) â†’ caffeine sensitivity insight
  taste(flavor profiles) + personality(openness) â†’ identity theme insight
  body(BMI trend) + lifestyle(exercise) â†’ fitness trajectory insight
    â†“
Cache in data/insights-cache.json (TTL: 1 hour)
    â†“
Return { insights: [...], generatedAt, domains }
```

**Key decisions:**
- Insights are computed on-demand (not scheduled) because the underlying data changes infrequently. A 1-hour TTL cache avoids repeated computation.
- Correlation rules are declarative data structures (not hardcoded if/else chains). Each rule specifies: `{ id, name, domains: ['genome', 'blood'], condition: fn, compute: fn, category }`. This makes it easy to add new correlations without touching engine logic.
- The engine is read-only â€” it never writes to source domains. It only reads from existing service exports.
- Start with genome-to-health and taste-to-identity correlations (user's stated priority), then expand the rule set.
- No AI provider needed for initial insights â€” these are deterministic rule-based correlations. AI-powered narrative summaries can layer on later.

### 4. Unified Search Flow

```
Client: Cmd+K input â†’ debounce 300ms â†’ GET /api/search?q=...&limit=20
    â†“
searchService.search(query, options)
    â†“
Fan-out (parallel):
  â”œâ”€â”€ brain: capturedThoughts.filter(match) â†’ { type: 'thought', ... }
  â”œâ”€â”€ memory: BM25 search (existing memoryBM25.js) â†’ { type: 'memory', ... }
  â”œâ”€â”€ apps: apps.json name/description match â†’ { type: 'app', ... }
  â”œâ”€â”€ history: activity log keyword match â†’ { type: 'activity', ... }
  â”œâ”€â”€ digital-twin: document content match â†’ { type: 'document', ... }
  â”œâ”€â”€ genome: SNP rsid match â†’ { type: 'snp', ... }
  â”œâ”€â”€ agents: personality name/description match â†’ { type: 'agent', ... }
  â””â”€â”€ meatspace: health record label match â†’ { type: 'health', ... }
    â†“
Merge results, assign category, sort by relevance score
    â†“
Return { results: [{ type, title, snippet, url, score }], timing }
```

**Key decisions:**
- Keyword-first (project constraint: semantic search is out of scope for v1). Each domain adapter does simple string matching or delegates to existing search (memory already has BM25).
- Fan-out is `Promise.allSettled()` â€” a failing domain must not break the entire search. Failed domains return empty results with a warning.
- Each domain adapter is a small function: `(query, limit) => [{ type, title, snippet, url, score }]`. This is the interface contract.
- Results include a `url` field (React Router path) so the Cmd+K overlay can navigate directly: e.g., `/brain/inbox`, `/meatspace/genome`, `/apps`.
- Response includes `timing` object so the UI can show "Searched 8 domains in 45ms".

### 5. Cmd+K Overlay Flow

```
User presses Cmd+K (or Ctrl+K)
    â†“
CommandPalette opens (modal overlay, z-50)
    â†“
User types query â†’ debounce 300ms â†’ api.get('/api/search?q=...')
    â†“
Results render in categories:
  ğŸ§  Thoughts (2)    ğŸ“± Apps (1)    ğŸ§¬ Genome (1)    ...
    â†“
Arrow keys navigate, Enter activates
    â†“
React Router navigate(result.url)
    â†“
CommandPalette closes
```

**Key decisions:**
- Global keyboard listener in `useCommandPalette.js` hook, rendered via `CommandPalette.jsx` inside `Layout.jsx` â€” wraps `<Outlet />`.
- No external dependency (cmdk, kbar). The component is straightforward: input + list + keyboard nav. External libraries add bundle weight for minimal gain in a single-user app.
- Empty state shows recent navigation or suggested actions (not blank).
- Escape closes. Clicking outside closes. Focus traps inside while open.

## Patterns to Follow

### Pattern 1: Service-per-Domain with Route Mounting

**What:** Each new feature gets its own service file and route file, mounted in `server/index.js`.
**When:** Always â€” this is the universal pattern in PortOS.
**Trade-offs:** More files, but clear boundaries. Every feature has exactly two touchpoints in `index.js` (import + mount).

```javascript
// server/index.js additions:
import backupRoutes from './routes/backup.js';
import insightsRoutes from './routes/insights.js';
import searchRoutes from './routes/search.js';

app.use('/api/backup', backupRoutes);
app.use('/api/insights', insightsRoutes);
app.use('/api/search', searchRoutes);

// Apple Health routes nest under existing meatspace mount:
// server/routes/meatspace.js â€” add health import routes
// OR mount separately: app.use('/api/meatspace/health', appleHealthRoutes);
```

### Pattern 2: Interval Scheduler (brainScheduler Pattern)

**What:** Use `setInterval` with a 60-second check loop that compares current time to target schedule. No cron dependency.
**When:** Backup scheduling.
**Trade-offs:** 60-second granularity (fine for daily backups). Avoids adding node-cron dependency. Consistent with brainScheduler.js which already does daily + weekly scheduling.

```javascript
// Same pattern as brainScheduler.js
const CHECK_INTERVAL_MS = 60000;
let schedulerInterval = null;

export function startBackupScheduler() {
  schedulerInterval = setInterval(checkSchedule, CHECK_INTERVAL_MS);
  console.log('ğŸ’¾ Backup scheduler started');
}
```

### Pattern 3: Aggregator Service (Fan-out + Merge)

**What:** A service that calls multiple other services in parallel and merges results.
**When:** Unified search and cross-insights engine.
**Trade-offs:** Creates a dependency on multiple services, but only read dependencies. Using `Promise.allSettled` ensures resilience.

```javascript
// server/services/search.js
const adapters = [
  { domain: 'brain', search: searchBrain },
  { domain: 'memory', search: searchMemory },
  { domain: 'apps', search: searchApps },
  // ...
];

export async function search(query, options = {}) {
  const results = await Promise.allSettled(
    adapters.map(a => a.search(query, options.limit))
  );
  // Merge fulfilled results, log rejected
  return mergeResults(results, adapters);
}
```

## Anti-Patterns to Avoid

### Anti-Pattern 1: DOM-Parsing Large XML

**What people do:** Use `DOMParser` or `xml2js` to parse the entire Apple Health XML into memory.
**Why it's wrong:** Apple Health exports are 200-500MB. Full DOM parse will exceed the 500MB memory limit and crash the process.
**Do this instead:** Use SAX/event-based streaming parser. Process records one at a time, write in batches.

### Anti-Pattern 2: Monolithic Search Function

**What people do:** Write one giant function that knows how to search every domain.
**Why it's wrong:** Tightly couples search to every data model. Adding a new searchable domain requires modifying the core function.
**Do this instead:** Use adapter pattern. Each domain registers a `(query, limit) => results[]` function. The search service only knows the adapter interface.

### Anti-Pattern 3: Synchronous Backup Blocking Server

**What people do:** Run rsync synchronously or await the entire copy in the request handler.
**Why it's wrong:** Backup can take minutes. Blocks the Express event loop or times out the HTTP request.
**Do this instead:** Spawn rsync as a child process. Return immediately with a job ID. Report progress via Socket.IO events.

### Anti-Pattern 4: Circular Service Dependencies in Insights

**What people do:** Have the insights service import from and write back to source services.
**Why it's wrong:** Creates bidirectional coupling. Source services should not know about insights.
**Do this instead:** Insights engine is strictly read-only. It imports from source services but never writes to them. Insights cache is its own data file.

## Integration Points

### Internal Boundaries

| Boundary | Communication | Notes |
|----------|---------------|-------|
| Search API â†” Domain Services | Direct function import (in-process) | Each adapter imports the relevant service. No HTTP between them. |
| Backup Service â†” File System | `child_process.spawn('rsync', [...])` | Async child process. Not blocking. |
| Apple Health Route â†” appleHealth Service | Direct function call (standard routeâ†’service pattern) | XML parsing happens in service layer, not route. |
| Insights Engine â†” Domain Services | Direct function import (read-only) | Insights never mutate source data. |
| Cmd+K â†” Search API | HTTP GET `/api/search` | Standard clientâ†’API pattern via `services/api.js`. |
| Backup/Search â†” Client | Socket.IO for real-time status | Backup progress events. Search uses HTTP (short-lived). |

### External Integrations

| Service | Integration Pattern | Notes |
|---------|---------------------|-------|
| External Drive | Mount path in `data/backup-config.json` | User configures once. Service validates mount exists before backup. |
| Health Auto Export App | HTTP POST to `/api/meatspace/health/import` | Third-party iOS app sends XML via HTTP. PortOS is the server. |
| rsync | `child_process.spawn` | macOS built-in. No npm dependency needed. |
| SAX XML Parser | npm dependency (`sax` or `saxes`) | Only new npm dependency across all five features. |

## Build Order and Dependencies

The five features have the following dependency graph:

```
M44 P6 (Cleanup)          â† No dependencies, pure cleanup
    â†“
M45 (Backup)              â† No dependencies on other new features
                             CRITICAL: protects ./data/ before adding more data
    â†“
M44 P7 (Apple Health)     â† Depends on meatspace infrastructure (already exists)
                             Should happen after backup is in place
    â†“
M42 P5 (Cross-Insights)   â† Depends on genome + health + taste data existing
                             Benefits from Apple Health data being available
    â†“
M46 (Unified Search)      â† Benefits from all data sources existing
                             Depends on no specific feature but searches everything
```

### Suggested Build Order Rationale

1. **M44 P6 (Cleanup)** â€” First because it fixes existing technical debt before building on top. Zero risk, zero dependencies.

2. **M45 (Backup)** â€” Second because it protects the single copy of all data in `./data/`. Every subsequent feature adds more data. Having backup in place before adding Apple Health bulk imports and insights caches is prudent.

3. **M44 P7 (Apple Health)** â€” Third because it adds a new data source that enriches the insights engine. The meatspace infrastructure already exists (routes, services, validation). This is additive.

4. **M42 P5 (Cross-Insights)** â€” Fourth because it benefits from having both genome data (already present) and Apple Health data (just added) to correlate. Building it before Apple Health would mean fewer correlations to ship.

5. **M46 (Unified Search)** â€” Last because it benefits from all data sources existing. Each domain adapter is independent, so search can ship incrementally, but the experience is richest when all domains are populated.

**Parallelism opportunity:** M44 P6 (cleanup) and M45 (backup) have zero overlap and can be built simultaneously. M44 P7 and M42 P5 are also parallelizable if the insights engine starts with genome-only correlations and adds health correlations when available. M46 is naturally incremental (add adapters one at a time).

## Scaling Considerations

| Concern | Current Scale (Single User) | If Data Grows 10x |
|---------|----------------------------|--------------------|
| Search latency | Fan-out across 8 JSON files, <100ms total | Add BM25 indexes for large domains (brain, health). Memory BM25 already exists. |
| Apple Health ingest | Stream parse handles 500MB+ files | Already using streaming â€” no change needed |
| Backup duration | rsync incremental on ~10MB of JSON | rsync handles this natively. Only changed files copy. |
| Insights computation | Read 5-6 JSON files, apply rules, <50ms | Cache TTL already handles this. No change needed. |
| Search index staleness | Keyword search reads live data on each query | Add in-memory caches with short TTL (2-5s) matching existing `appsCache` pattern |

PortOS is single-user, so horizontal scaling is not a concern. The bottleneck sequence is: (1) Apple Health file size during ingest, (2) search fan-out latency if data files grow very large. Both are addressed by the streaming and caching patterns already described.

## Sources

- PortOS codebase analysis: `server/index.js`, `ecosystem.config.cjs`, `server/services/brainScheduler.js`, `server/lib/bm25.js`, `server/services/memoryBM25.js` â€” HIGH confidence (direct code inspection)
- PortOS architecture docs: `.planning/codebase/ARCHITECTURE.md`, `.planning/codebase/STRUCTURE.md` â€” HIGH confidence
- SAX XML parsing: established Node.js pattern for large XML processing â€” HIGH confidence (training data + long-standing community practice)
- rsync incremental backup: macOS built-in utility, well-documented â€” HIGH confidence

---
*Architecture research for: PortOS next actions batch*
*Researched: 2026-02-26*
